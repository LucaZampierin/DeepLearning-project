{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qj3b9-BKHt6M"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyJRsinDzJc4",
        "outputId": "f01dfa23-81ca-456e-e91e-7ab7728da90c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#content/drive/MyDrive/Colab Notebooks/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PLdbqPt8I0A7"
      },
      "outputs": [],
      "source": [
        "noisy_imgs1, noisy_imgs2 = torch.load('train_data.pkl') # 50000 x 3 x 32 x 32\n",
        "noisy_val, clean_val = torch.load('val_data.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "m7fkiwvXJmom"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'def psnr(denoised, ground_truth):\\n  mse = torch.mean((denoised - ground_truth) ** 2)\\n  return -10*torch.log10(mse + 10 ** -8)\\n  '"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''def psnr(denoised, ground_truth):\n",
        "  mse = torch.mean((denoised - ground_truth) ** 2)\n",
        "  return -10*torch.log10(mse + 10 ** -8)\n",
        "  '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def psnr(denoised, ground_truth):\n",
        "  mse = torch.mean((denoised - ground_truth) ** 2)\n",
        "  return 20 * torch.log10(torch.full((1, 1), 255).to(\"cuda\")) - 10 * torch.log10(mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x7krHeH9NWOl"
      },
      "outputs": [],
      "source": [
        "def validate(model, noise_img, ground_truth):\n",
        "  psnr_tot = 0\n",
        "  if torch.cuda.is_available():\n",
        "      noise_img, ground_truth = noise_img.to(\"cuda\"), ground_truth.to(\"cuda\")\n",
        "  for i in range(noise_img.size(0)):\n",
        "    denoised = model(noise_img[i].view(1, 3, 32, 32))\n",
        "    #print(noise_img[i])\n",
        "    psnr_val = psnr(denoised, ground_truth[i]).item()\n",
        "    #print(psnr_val)\n",
        "    psnr_tot += psnr_val\n",
        "  psnr_tot /= noise_img.size(0)\n",
        "  return psnr_tot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7t9yy00H7PHb"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_input, train_target, criterion, optimizer, mini_batch_size=4, epochs=500, normalize=False):\n",
        "    if torch.cuda.is_available():\n",
        "      model.to(\"cuda\")\n",
        "      train_input, train_target = train_input.to(\"cuda\"), train_target.to(\"cuda\")\n",
        "    if normalize:\n",
        "      mu, std = train_input.mean(), train_input.std()\n",
        "      train_input.sub_(mu).div_(std)\n",
        "\n",
        "    for e in range(epochs):\n",
        "      avg_loss = 0\n",
        "      for b in range(0, train_input.size(0), mini_batch_size):\n",
        "          output = model(train_input.narrow(0, b, mini_batch_size))\n",
        "          loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
        "          avg_loss += loss\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "      print(f\"Loss at {e} is {avg_loss / (train_input.size(0) / mini_batch_size)}\")\n",
        "      print(f\"PSNR: {validate(model, noisy_val.float(), clean_val.float())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YDnQT6D-K3SM"
      },
      "outputs": [],
      "source": [
        "class SuperbModel(torch.nn.Module):\n",
        "    def __init__(self, transposed_conv=False):\n",
        "        super().__init__()\n",
        "        self.enc_conv0 = nn.Conv2d(3, 48, (3, 3), padding='same')\n",
        "        self.enc_conv1 = nn.Conv2d(48, 48, (3, 3), padding='same')\n",
        "        self.enc_conv2 = nn.Conv2d(48, 48, (3, 3), padding='same')\n",
        "        self.enc_conv3 = nn.Conv2d(48, 48, (3, 3), padding='same')\n",
        "        self.enc_conv4 = nn.Conv2d(48, 48, (3, 3), padding='same')\n",
        "        self.enc_conv5 = nn.Conv2d(48, 48, (3, 3), padding='same')\n",
        "        self.enc_conv6 = nn.Conv2d(48, 48, (3, 3), padding='same')\n",
        "        self.upsample5 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "                  # concatenation \n",
        "        self.dec_conv5a = nn.Conv2d(96, 96, (3, 3), padding='same')\n",
        "        self.dec_conv5b = nn.Conv2d(96, 96, (3, 3), padding='same')\n",
        "        self.upsample4 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "                  # concatenation\n",
        "        self.dec_conv4a = nn.Conv2d(144, 96, (3, 3), padding='same')\n",
        "        self.dec_conv4b = nn.Conv2d(96, 96, (3, 3), padding='same')\n",
        "        self.upsample3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "                  # concatenation\n",
        "        self.dec_conv3a = nn.Conv2d(144, 96, (3, 3), padding='same')\n",
        "        self.dec_conv3b = nn.Conv2d(96, 96, (3, 3), padding='same')\n",
        "        self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "                  # concatenatio\n",
        "        self.dec_conv2a = nn.Conv2d(144, 96, (3, 3), padding='same')\n",
        "        self.dec_conv2b = nn.Conv2d(96, 96, (3, 3), padding='same')\n",
        "        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "                  # concatenation\n",
        "        self.custom = nn.Conv2d(144, 99, (3, 3), padding='same')\n",
        "        self.dec_conv1a = nn.Conv2d(96 + 3, 64, (3, 3), padding='same')\n",
        "        self.dec_conv1b = nn.Conv2d(64, 32, (3, 3), padding='same')\n",
        "        self.dec_conv1c = nn.Conv2d(32, 3, (3, 3), padding='same')\n",
        "                  #what does linear activation mean (output unchanged?)\n",
        "\n",
        "    def forward(self, x):\n",
        "      input = x.clone()\n",
        "      x = F.leaky_relu(self.enc_conv0(x), negative_slope=0.1)\n",
        "      x = F.leaky_relu(self.enc_conv1(x), negative_slope=0.1)\n",
        "      #pool1 = F.max_pool2d(x, 2)\n",
        "      #x = F.leaky_relu(self.enc_conv2(pool1), negative_slope=0.1)\n",
        "      '''pool2 = F.max_pool2d(x, 2)\n",
        "      x = F.leaky_relu(self.enc_conv3(pool2), negative_slope=0.1)'''\n",
        "      pool3 = F.max_pool2d(x, 2) #MAKE SURE THEY HAVE CORRECT VALUES AND THEY ARE NOT CHANGED BY FOLLOWING OPERATIONS\n",
        "      x = F.leaky_relu(self.enc_conv4(pool3), negative_slope=0.1)\n",
        "      pool4 = F.max_pool2d(x, 2)\n",
        "      x = F.leaky_relu(self.enc_conv5(pool4), negative_slope=0.1)\n",
        "      ''' pool5 = F.max_pool2d(x, 2)\n",
        "      x = F.leaky_relu(self.enc_conv6(pool5), negative_slope=0.1)\n",
        "      x = self.upsample5(x)'''\n",
        "      x = torch.cat((x, pool4), dim=1)#.view(-1, 96, 2, 2) #MAKE SURE THEY ARE STACKED ON THE CORRECT DIMENSIONS\n",
        "      '''x = F.leaky_relu(self.dec_conv5a(x), negative_slope=0.1)\n",
        "      x = F.leaky_relu(self.dec_conv5b(x), negative_slope=0.1)\n",
        "      x = self.upsample4(x) \n",
        "      x = torch.cat((x, pool3), dim=1)\n",
        "      \n",
        "      x = F.leaky_relu(self.dec_conv4a(x), negative_slope=0.1)\n",
        "      x = F.leaky_relu(self.dec_conv4b(x), negative_slope=0.1)\n",
        "      x = self.upsample3(x) \n",
        "      x = torch.cat((x, pool2), dim=1)'''\n",
        "      x = self.upsample3(x) # custom\n",
        "      x = torch.cat((x, pool3), dim=1) #custom\n",
        "      x = F.leaky_relu(self.dec_conv3a(x), negative_slope=0.1)\n",
        "      x = F.leaky_relu(self.dec_conv3b(x), negative_slope=0.1)\n",
        "      x = self.upsample2(x) \n",
        "      #x = torch.cat((x, pool1), dim=1)\n",
        "      '''\n",
        "      x = F.leaky_relu(self.dec_conv2a(x), negative_slope=0.1)\n",
        "      x = F.leaky_relu(self.dec_conv2b(x), negative_slope=0.1)\n",
        "      x = self.upsample1(x) '''\n",
        "      x = torch.cat((x, input), dim=1)\n",
        "      #x = F.leaky_relu(self.custom(x), negative_slope=0.1) #custom\n",
        "      x = F.leaky_relu(self.dec_conv1a(x), negative_slope=0.1)\n",
        "      x = self.upsample1(x) #custom\n",
        "      x = F.leaky_relu(self.dec_conv1b(x), negative_slope=0.1)\n",
        "      x = F.max_pool2d(x, 2) #custom\n",
        "      x = self.dec_conv1c(x)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QD5d-nJvzFm7"
      },
      "outputs": [],
      "source": [
        "class LeanerModel(torch.nn.Module):\n",
        "    def __init__(self, transposed_conv=False):\n",
        "        super().__init__()\n",
        "        self.enc_conv0 = nn.Conv2d(3, 16, (3, 3), padding='same')\n",
        "        self.enc_conv1 = nn.Conv2d(16, 32, (3, 3), padding='same')\n",
        "        self.enc_conv3 = nn.Conv2d(32, 32, (3, 3), padding='same')\n",
        "                  # concatenation\n",
        "        self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "                  # concatenatio\n",
        "        self.dec_conv2a = nn.Conv2d(64, 64, (3, 3), padding='same')\n",
        "        self.dec_conv2b = nn.Conv2d(64, 64, (3, 3), padding='same')\n",
        "        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "                  # concatenation\n",
        "        self.dec_conv1a = nn.Conv2d(67, 32, (3, 3), padding='same')\n",
        "        self.dec_conv1b = nn.Conv2d(32, 16, (3, 3), padding='same')\n",
        "        self.dec_conv1c = nn.Conv2d(16, 3, (3, 3), padding='same')\n",
        "                  #what does linear activation mean (output unchanged?)\n",
        "\n",
        "    def forward(self, x):\n",
        "      input = x.clone()\n",
        "      x = F.leaky_relu(self.enc_conv0(x), negative_slope=0.1)\n",
        "      x = F.leaky_relu(self.enc_conv1(x), negative_slope=0.1)\n",
        "      pool1 = F.max_pool2d(x, 2) #32x16x16\n",
        "      x = F.leaky_relu(self.enc_conv3(pool1), negative_slope=0.1)\n",
        "      #pool3 = F.max_pool2d(x, 2) #48x8x8\n",
        "      #x = self.upsample2(x) #48x32x32\n",
        "      x = torch.cat((x, pool1), dim=1)#64x16x16\n",
        "      x = F.leaky_relu(self.dec_conv2a(x), negative_slope=0.1)\n",
        "      #x = F.leaky_relu(self.dec_conv2b(x), negative_slope=0.1)\n",
        "      x = self.upsample1(x)  #64x32x32\n",
        "      x = torch.cat((x, input), dim=1) #67x32x32\n",
        "      x = F.leaky_relu(self.dec_conv1a(x), negative_slope=0.1)\n",
        "      x = F.leaky_relu(self.dec_conv1b(x), negative_slope=0.1)\n",
        "      x = self.dec_conv1c(x)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2e3MRORcy05",
        "outputId": "9473f507-1b93-4a16-c8ea-126560fa7e63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ogXoYG1kJL19",
        "outputId": "dd1cc70e-314e-42a0-9ac7-1117b2178760"
      },
      "outputs": [],
      "source": [
        "model = LeanerModel()\n",
        "train_model(model, noisy_imgs1.float(), noisy_imgs2.float(), nn.MSELoss(), torch.optim.Adam(model.parameters()), 50, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'leaner_model1_3.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un1oCewLJC9o",
        "outputId": "cf935d8f-4ce4-4857-b044-f1c357a65d49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24.442471048355102\n"
          ]
        }
      ],
      "source": [
        "model = LeanerModel()\n",
        "model.load_state_dict(torch.load('models/leaner_model1.pt'))\n",
        "print(validate(model.to(\"cuda\"), noisy_val.float(), clean_val.float()))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DummyCodeDL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
