{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DummyCodeDL.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMTT7uR5RoLiVSERptVkmIG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Qj3b9-BKHt6M"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CjLe8QuZ9J4e","executionInfo":{"status":"ok","timestamp":1650265833284,"user_tz":-120,"elapsed":20065,"user":{"displayName":"Saverio Nasturzio","userId":"16018184137939682535"}},"outputId":"e8c37ab8-8504-4530-ee70-1869361292b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["noisy_imgs1, noisy_imgs2 = torch.load('/content/drive/MyDrive/Colab Notebooks/train_data.pkl') # 50000 x 3 x 32 x 32\n","noisy_val, clean_val = torch.load('/content/drive/MyDrive/Colab Notebooks/val_data.pkl')"],"metadata":{"id":"PLdbqPt8I0A7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def psnr(denoised, ground_truth):\n","  mse = torch.mean((denoised - ground_truth) ** 2)\n","  return -10*torch.log10(mse + 10 ** -8)"],"metadata":{"id":"m7fkiwvXJmom"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model, train_input, train_target, criterion, optimizer, mini_batch_size=4, epochs=500, normalize=False):\n","    if torch.cuda.is_available():\n","      model.to(\"cuda\")\n","      train_input, train_target = train_input.to(\"cuda\"), train_target.to(\"cuda\")\n","    if normalize:\n","      mu, std = train_input.mean(), train_input.std()\n","      train_input.sub_(mu).div_(std)\n","\n","    for e in range(epochs):\n","      print(e)\n","      for b in range(0, train_input.size(0), mini_batch_size):\n","          output = model(train_input.narrow(0, b, mini_batch_size))\n","          loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()"],"metadata":{"id":"7t9yy00H7PHb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SuperbModel(torch.nn.Module):\n","    def __init__(self, transposed_conv=False):\n","        super().__init__()\n","        self.enc_conv0 = nn.Conv2d(3, 48, (3, 3), padding='same')\n","        self.enc_conv1 = nn.Conv2d(48, 48, (3, 3), padding='same')\n","        self.enc_conv2 = nn.Conv2d(48, 48, (3, 3), padding='same')\n","        self.enc_conv3 = nn.Conv2d(48, 48, (3, 3), padding='same')\n","        self.enc_conv4 = nn.Conv2d(48, 48, (3, 3), padding='same')\n","        self.enc_conv5 = nn.Conv2d(48, 48, (3, 3), padding='same')\n","        self.enc_conv6 = nn.Conv2d(48, 48, (3, 3), padding='same')\n","        self.upsample5 = nn.UpsamplingNearest2d(scale_factor=2)\n","                  # concatenation \n","        self.dec_conv5a = nn.Conv2d(96, 96, (3, 3), padding='same')\n","        self.dec_conv5b = nn.Conv2d(96, 96, (3, 3), padding='same')\n","        self.upsample4 = nn.UpsamplingNearest2d(scale_factor=2)\n","                  # concatenation\n","        self.dec_conv4a = nn.Conv2d(144, 96, (3, 3), padding='same')\n","        self.dec_conv4b = nn.Conv2d(96, 96, (3, 3), padding='same')\n","        self.upsample3 = nn.UpsamplingNearest2d(scale_factor=2)\n","                  # concatenation\n","        self.dec_conv3a = nn.Conv2d(144, 96, (3, 3), padding='same')\n","        self.dec_conv3b = nn.Conv2d(96, 96, (3, 3), padding='same')\n","        self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2)\n","                  # concatenatio\n","        self.dec_conv2a = nn.Conv2d(144, 96, (3, 3), padding='same')\n","        self.dec_conv2b = nn.Conv2d(96, 96, (3, 3), padding='same')\n","        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=2)\n","                  # concatenation\n","        self.custom = nn.Conv2d(144, 99, (3, 3), padding='same')\n","        self.dec_conv1a = nn.Conv2d(96 + 3, 64, (3, 3), padding='same')\n","        self.dec_conv1b = nn.Conv2d(64, 32, (3, 3), padding='same')\n","        self.dec_conv1c = nn.Conv2d(32, 3, (3, 3), padding='same')\n","                  #what does linear activation mean (output unchanged?)\n","\n","    def forward(self, x):\n","      input = x.clone()\n","      x = F.leaky_relu(self.enc_conv0(x), negative_slope=0.1)\n","      x = F.leaky_relu(self.enc_conv1(x), negative_slope=0.1)\n","      #pool1 = F.max_pool2d(x, 2)\n","      #x = F.leaky_relu(self.enc_conv2(pool1), negative_slope=0.1)\n","      '''pool2 = F.max_pool2d(x, 2)\n","      x = F.leaky_relu(self.enc_conv3(pool2), negative_slope=0.1)'''\n","      pool3 = F.max_pool2d(x, 2) #MAKE SURE THEY HAVE CORRECT VALUES AND THEY ARE NOT CHANGED BY FOLLOWING OPERATIONS\n","      x = F.leaky_relu(self.enc_conv4(pool3), negative_slope=0.1)\n","      pool4 = F.max_pool2d(x, 2)\n","      x = F.leaky_relu(self.enc_conv5(pool4), negative_slope=0.1)\n","      ''' pool5 = F.max_pool2d(x, 2)\n","      x = F.leaky_relu(self.enc_conv6(pool5), negative_slope=0.1)\n","      x = self.upsample5(x)'''\n","      x = torch.cat((x, pool4), dim=1)#.view(-1, 96, 2, 2) #MAKE SURE THEY ARE STACKED ON THE CORRECT DIMENSIONS\n","      '''x = F.leaky_relu(self.dec_conv5a(x), negative_slope=0.1)\n","      x = F.leaky_relu(self.dec_conv5b(x), negative_slope=0.1)\n","      x = self.upsample4(x) \n","      x = torch.cat((x, pool3), dim=1)\n","      \n","      x = F.leaky_relu(self.dec_conv4a(x), negative_slope=0.1)\n","      x = F.leaky_relu(self.dec_conv4b(x), negative_slope=0.1)\n","      x = self.upsample3(x) \n","      x = torch.cat((x, pool2), dim=1)'''\n","      x = self.upsample3(x) # custom\n","      x = torch.cat((x, pool3), dim=1) #custom\n","      x = F.leaky_relu(self.dec_conv3a(x), negative_slope=0.1)\n","      x = F.leaky_relu(self.dec_conv3b(x), negative_slope=0.1)\n","      x = self.upsample2(x) \n","      #x = torch.cat((x, pool1), dim=1)\n","      '''\n","      x = F.leaky_relu(self.dec_conv2a(x), negative_slope=0.1)\n","      x = F.leaky_relu(self.dec_conv2b(x), negative_slope=0.1)\n","      x = self.upsample1(x) '''\n","      x = torch.cat((x, input), dim=1)\n","      #x = F.leaky_relu(self.custom(x), negative_slope=0.1) #custom\n","      x = F.leaky_relu(self.dec_conv1a(x), negative_slope=0.1)\n","      x = self.upsample1(x) #custom\n","      x = F.leaky_relu(self.dec_conv1b(x), negative_slope=0.1)\n","      x = F.max_pool2d(x, 2) #custom\n","      x = self.dec_conv1c(x)\n","      return x"],"metadata":{"id":"YDnQT6D-K3SM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(torch.cuda.is_available())"],"metadata":{"id":"S2e3MRORcy05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = SuperbModel()\n","train_model(model, noisy_imgs1.float(), noisy_imgs2.float(), nn.MSELoss(), torch.optim.Adam(model.parameters()), 100, 100)\n","torch.save(model.state_dict(), 'mymodule.pt')"],"metadata":{"id":"ogXoYG1kJL19","colab":{"base_uri":"https://localhost:8080/"},"outputId":"04fb7468-a6f3-407f-c0c8-abb97cdcd728"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n"]}]}]}