{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Qj3b9-BKHt6M"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"PLdbqPt8I0A7"},"outputs":[],"source":["noisy_imgs1, noisy_imgs2 = torch.load('train_data.pkl') # 50000 x 3 x 32 x 32\n","noisy_val, clean_val = torch.load('val_data.pkl')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"m7fkiwvXJmom"},"outputs":[],"source":["def psnr(denoised, ground_truth):\n","  mse = torch.mean((denoised - ground_truth) ** 2)\n","  return -10*torch.log10(mse + 10 ** -8)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"7t9yy00H7PHb"},"outputs":[],"source":["def train_model(model, train_input, train_target, criterion, optimizer, mini_batch_size=4, epochs=500, normalize=False):\n","    if torch.cuda.is_available():\n","      model.to(\"cuda\")\n","      train_input, train_target = train_input.to(\"cuda\"), train_target.to(\"cuda\")\n","    if normalize:\n","      mu, std = train_input.mean(), train_input.std()\n","      train_input.sub_(mu).div_(std)\n","\n","    for e in range(epochs):\n","      print(e)\n","      for b in range(0, train_input.size(0), mini_batch_size):\n","          output = model(train_input.narrow(0, b, mini_batch_size))\n","          loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"YDnQT6D-K3SM"},"outputs":[],"source":["class SuperbModel(torch.nn.Module):\n","    def __init__(self, transposed_conv=False):\n","        super().__init__()\n","        self.enc_conv0 = nn.Conv2d(3, 48, (3, 3), padding='same')\n","        self.enc_conv1 = nn.Conv2d(48, 48, (3, 3), padding='same')\n","        self.enc_conv2 = nn.Conv2d(48, 48, (3, 3), padding='same')\n","        self.enc_conv3 = nn.Conv2d(48, 48, (3, 3), padding='same')\n","        self.enc_conv4 = nn.Conv2d(48, 48, (3, 3), padding='same')\n","        self.enc_conv5 = nn.Conv2d(48, 48, (3, 3), padding='same')\n","        self.enc_conv6 = nn.Conv2d(48, 48, (3, 3), padding='same')\n","        self.upsample5 = nn.UpsamplingNearest2d(scale_factor=2)\n","                  # concatenation \n","        self.dec_conv5a = nn.Conv2d(96, 96, (3, 3), padding='same')\n","        self.dec_conv5b = nn.Conv2d(96, 96, (3, 3), padding='same')\n","        self.upsample4 = nn.UpsamplingNearest2d(scale_factor=2)\n","                  # concatenation\n","        self.dec_conv4a = nn.Conv2d(144, 96, (3, 3), padding='same')\n","        self.dec_conv4b = nn.Conv2d(96, 96, (3, 3), padding='same')\n","        self.upsample3 = nn.UpsamplingNearest2d(scale_factor=2)\n","                  # concatenation\n","        self.dec_conv3a = nn.Conv2d(144, 96, (3, 3), padding='same')\n","        self.dec_conv3b = nn.Conv2d(96, 96, (3, 3), padding='same')\n","        self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2)\n","                  # concatenatio\n","        self.dec_conv2a = nn.Conv2d(144, 96, (3, 3), padding='same')\n","        self.dec_conv2b = nn.Conv2d(96, 96, (3, 3), padding='same')\n","        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=2)\n","                  # concatenation\n","        self.custom = nn.Conv2d(144, 99, (3, 3), padding='same')\n","        self.dec_conv1a = nn.Conv2d(96 + 3, 64, (3, 3), padding='same')\n","        self.dec_conv1b = nn.Conv2d(64, 32, (3, 3), padding='same')\n","        self.dec_conv1c = nn.Conv2d(32, 3, (3, 3), padding='same')\n","                  #what does linear activation mean (output unchanged?)\n","\n","    def forward(self, x):\n","      input = x.clone()\n","      x = F.leaky_relu(self.enc_conv0(x), negative_slope=0.1)\n","      x = F.leaky_relu(self.enc_conv1(x), negative_slope=0.1)\n","      #pool1 = F.max_pool2d(x, 2)\n","      #x = F.leaky_relu(self.enc_conv2(pool1), negative_slope=0.1)\n","      '''pool2 = F.max_pool2d(x, 2)\n","      x = F.leaky_relu(self.enc_conv3(pool2), negative_slope=0.1)'''\n","      pool3 = F.max_pool2d(x, 2) #MAKE SURE THEY HAVE CORRECT VALUES AND THEY ARE NOT CHANGED BY FOLLOWING OPERATIONS\n","      x = F.leaky_relu(self.enc_conv4(pool3), negative_slope=0.1)\n","      pool4 = F.max_pool2d(x, 2)\n","      x = F.leaky_relu(self.enc_conv5(pool4), negative_slope=0.1)\n","      ''' pool5 = F.max_pool2d(x, 2)\n","      x = F.leaky_relu(self.enc_conv6(pool5), negative_slope=0.1)\n","      x = self.upsample5(x)'''\n","      x = torch.cat((x, pool4), dim=1)#.view(-1, 96, 2, 2) #MAKE SURE THEY ARE STACKED ON THE CORRECT DIMENSIONS\n","      '''x = F.leaky_relu(self.dec_conv5a(x), negative_slope=0.1)\n","      x = F.leaky_relu(self.dec_conv5b(x), negative_slope=0.1)\n","      x = self.upsample4(x) \n","      x = torch.cat((x, pool3), dim=1)\n","      \n","      x = F.leaky_relu(self.dec_conv4a(x), negative_slope=0.1)\n","      x = F.leaky_relu(self.dec_conv4b(x), negative_slope=0.1)\n","      x = self.upsample3(x) \n","      x = torch.cat((x, pool2), dim=1)'''\n","      x = self.upsample3(x) # custom\n","      x = torch.cat((x, pool3), dim=1) #custom\n","      x = F.leaky_relu(self.dec_conv3a(x), negative_slope=0.1)\n","      x = F.leaky_relu(self.dec_conv3b(x), negative_slope=0.1)\n","      x = self.upsample2(x) \n","      #x = torch.cat((x, pool1), dim=1)\n","      '''\n","      x = F.leaky_relu(self.dec_conv2a(x), negative_slope=0.1)\n","      x = F.leaky_relu(self.dec_conv2b(x), negative_slope=0.1)\n","      x = self.upsample1(x) '''\n","      x = torch.cat((x, input), dim=1)\n","      #x = F.leaky_relu(self.custom(x), negative_slope=0.1) #custom\n","      x = F.leaky_relu(self.dec_conv1a(x), negative_slope=0.1)\n","      x = self.upsample1(x) #custom\n","      x = F.leaky_relu(self.dec_conv1b(x), negative_slope=0.1)\n","      x = F.max_pool2d(x, 2) #custom\n","      x = self.dec_conv1c(x)\n","      return x"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["class LeanerModel(torch.nn.Module):\n","    def __init__(self, transposed_conv=False):\n","        super().__init__()\n","        self.enc_conv0 = nn.Conv2d(3, 48, (3, 3), padding='same')\n","        self.enc_conv1 = nn.Conv2d(48, 48, (3, 3), padding='same')\n","        self.enc_conv3 = nn.Conv2d(48, 48, (3, 3), padding='same')\n","                  # concatenation\n","        self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2)\n","                  # concatenatio\n","        self.dec_conv2a = nn.Conv2d(96, 96, (3, 3), padding='same')\n","        self.dec_conv2b = nn.Conv2d(96, 96, (3, 3), padding='same')\n","        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=2)\n","                  # concatenation\n","        self.custom = nn.Conv2d(144, 99, (3, 3), padding='same')\n","        self.dec_conv1a = nn.Conv2d(96 + 3, 64, (3, 3), padding='same')\n","        self.dec_conv1b = nn.Conv2d(64, 32, (3, 3), padding='same')\n","        self.dec_conv1c = nn.Conv2d(32, 3, (3, 3), padding='same')\n","                  #what does linear activation mean (output unchanged?)\n","\n","    def forward(self, x):\n","      input = x.clone()\n","      x = F.leaky_relu(self.enc_conv0(x), negative_slope=0.1)\n","      x = F.leaky_relu(self.enc_conv1(x), negative_slope=0.1)\n","      pool1 = F.max_pool2d(x, 2) #48x16x16\n","      x = F.leaky_relu(self.enc_conv3(pool1), negative_slope=0.1)\n","      #pool3 = F.max_pool2d(x, 2) #48x8x8\n","      #x = self.upsample2(x) #48x32x32\n","      x = torch.cat((x, pool1), dim=1)#96x16x16\n","      x = F.leaky_relu(self.dec_conv2a(x), negative_slope=0.1)\n","      x = F.leaky_relu(self.dec_conv2b(x), negative_slope=0.1)\n","      x = self.upsample1(x)  #96x32x32\n","      x = torch.cat((x, input), dim=1) #99x32x32\n","      x = F.leaky_relu(self.dec_conv1a(x), negative_slope=0.1)\n","      x = F.leaky_relu(self.dec_conv1b(x), negative_slope=0.1)\n","      x = self.dec_conv1c(x)\n","      return x"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"S2e3MRORcy05"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n"]}],"source":["print(torch.cuda.is_available())"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ogXoYG1kJL19","outputId":"04fb7468-a6f3-407f-c0c8-abb97cdcd728"},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32md:\\EPFL\\dl\\Miniproject1\\DeepLearning-project\\UNetNoise2Noise.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000007?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m SuperbModel()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000007?line=1'>2</a>\u001b[0m train_model(model, noisy_imgs1\u001b[39m.\u001b[39;49mfloat(), noisy_imgs2\u001b[39m.\u001b[39;49mfloat(), nn\u001b[39m.\u001b[39;49mMSELoss(), torch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdam(model\u001b[39m.\u001b[39;49mparameters()), \u001b[39m500\u001b[39;49m, \u001b[39m100\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000007?line=2'>3</a>\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), \u001b[39m'\u001b[39m\u001b[39mmymodule.pt\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[1;32md:\\EPFL\\dl\\Miniproject1\\DeepLearning-project\\UNetNoise2Noise.ipynb Cell 4'\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_input, train_target, criterion, optimizer, mini_batch_size, epochs, normalize)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000004?line=12'>13</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, train_target\u001b[39m.\u001b[39mnarrow(\u001b[39m0\u001b[39m, b, mini_batch_size))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000004?line=13'>14</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000004?line=14'>15</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000004?line=15'>16</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n","File \u001b[1;32mD:\\Programmi\\Python3\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n","File \u001b[1;32mD:\\Programmi\\Python3\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model = SuperbModel()\n","train_model(model, noisy_imgs1.float(), noisy_imgs2.float(), nn.MSELoss(), torch.optim.Adam(model.parameters()), 500, 100)\n","torch.save(model.state_dict(), 'mymodule.pt')"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMTT7uR5RoLiVSERptVkmIG","collapsed_sections":[],"name":"DummyCodeDL.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
