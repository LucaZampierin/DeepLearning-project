{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qj3b9-BKHt6M"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyJRsinDzJc4",
        "outputId": "f01dfa23-81ca-456e-e91e-7ab7728da90c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"from google.colab import drive\\ndrive.mount('/content/drive')\\nimport sys\\nsys.path.append('/content/drive/MyDrive/Colab Notebooks/')\""
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#/content/drive/MyDrive/Colab Notebooks/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PLdbqPt8I0A7"
      },
      "outputs": [],
      "source": [
        "noisy_imgs1, noisy_imgs2 = torch.load('train_data.pkl') # 50000 x 3 x 32 x 32\n",
        "noisy_val, clean_val = torch.load('val_data.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m7fkiwvXJmom"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'def psnr(denoised, ground_truth):\\n  mse = torch.mean((denoised - ground_truth) ** 2)\\n  return -10*torch.log10(mse + 10 ** -8)\\n  '"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''def psnr(denoised, ground_truth):\n",
        "  mse = torch.mean((denoised - ground_truth) ** 2)\n",
        "  return -10*torch.log10(mse + 10 ** -8)\n",
        "  '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def psnr(x, y, max_range=255):\n",
        "  assert x.shape == y.shape and x.ndim == 4\n",
        "  return 20 * torch.log10(torch.tensor(max_range)) - 10 * torch.log10(((x-y) ** 2).mean((1,2,3))).mean()\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x7krHeH9NWOl"
      },
      "outputs": [],
      "source": [
        "def validate(model, noise_img, ground_truth):\n",
        "  if torch.cuda.is_available():\n",
        "      noise_img, ground_truth = noise_img.to(\"cuda\"), ground_truth.to(\"cuda\")\n",
        "  with torch.no_grad():\n",
        "    res = psnr(model(noise_img.float()), ground_truth.float())\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7t9yy00H7PHb"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_input, train_target, criterion, optimizer, mini_batch_size=4, epochs=500, normalize=False):\n",
        "    if torch.cuda.is_available():\n",
        "      model.to(\"cuda\")\n",
        "      train_input, train_target = train_input.to(\"cuda\"), train_target.to(\"cuda\")\n",
        "    if normalize:\n",
        "      mu, std = train_input.mean(), train_input.std()\n",
        "      train_input.sub_(mu).div_(std)\n",
        "\n",
        "    for e in range(epochs):\n",
        "      avg_loss = 0\n",
        "      for b in range(0, train_input.size(0), mini_batch_size):\n",
        "          output = model(train_input.narrow(0, b, mini_batch_size))\n",
        "          loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
        "          avg_loss += loss\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "      print(f\"Loss at {e} is {avg_loss / (train_input.size(0) / mini_batch_size)}\")\n",
        "      print(f\"PSNR: {validate(model, noisy_val.float(), clean_val.float())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YDnQT6D-K3SM"
      },
      "outputs": [],
      "source": [
        "class SuperbModel(torch.nn.Module):\n",
        "    def __init__(self, transposed_conv=False):\n",
        "        super().__init__()\n",
        "        self.enc_conv0 = nn.Conv2d(3, 48, (3, 3), padding='same')\n",
        "        self.enc_conv1 = nn.Conv2d(48, 48, (3, 3), padding='same')\n",
        "        self.enc_conv2 = nn.Conv2d(48, 48, (3, 3), padding='same')\n",
        "        self.enc_conv3 = nn.Conv2d(48, 48, (3, 3), padding='same')\n",
        "        self.enc_conv4 = nn.Conv2d(48, 48, (3, 3), padding='same')\n",
        "        self.enc_conv5 = nn.Conv2d(48, 48, (3, 3), padding='same')\n",
        "        self.enc_conv6 = nn.Conv2d(48, 48, (3, 3), padding='same')\n",
        "        self.upsample5 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "                  # concatenation \n",
        "        self.dec_conv5a = nn.Conv2d(96, 96, (3, 3), padding='same')\n",
        "        self.dec_conv5b = nn.Conv2d(96, 96, (3, 3), padding='same')\n",
        "        self.upsample4 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "                  # concatenation\n",
        "        self.dec_conv4a = nn.Conv2d(144, 96, (3, 3), padding='same')\n",
        "        self.dec_conv4b = nn.Conv2d(96, 96, (3, 3), padding='same')\n",
        "        self.upsample3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "                  # concatenation\n",
        "        self.dec_conv3a = nn.Conv2d(144, 96, (3, 3), padding='same')\n",
        "        self.dec_conv3b = nn.Conv2d(96, 96, (3, 3), padding='same')\n",
        "        self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "                  # concatenatio\n",
        "        self.dec_conv2a = nn.Conv2d(144, 96, (3, 3), padding='same')\n",
        "        self.dec_conv2b = nn.Conv2d(96, 96, (3, 3), padding='same')\n",
        "        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "                  # concatenation\n",
        "        self.custom = nn.Conv2d(144, 99, (3, 3), padding='same')\n",
        "        self.dec_conv1a = nn.Conv2d(96 + 3, 64, (3, 3), padding='same')\n",
        "        self.dec_conv1b = nn.Conv2d(64, 32, (3, 3), padding='same')\n",
        "        self.dec_conv1c = nn.Conv2d(32, 3, (3, 3), padding='same')\n",
        "                  #what does linear activation mean (output unchanged?)\n",
        "\n",
        "    def forward(self, x):\n",
        "      input = x.clone()\n",
        "      x = F.leaky_relu(self.enc_conv0(x), negative_slope=0.1)\n",
        "      x = F.leaky_relu(self.enc_conv1(x), negative_slope=0.1)\n",
        "      #pool1 = F.max_pool2d(x, 2)\n",
        "      #x = F.leaky_relu(self.enc_conv2(pool1), negative_slope=0.1)\n",
        "      '''pool2 = F.max_pool2d(x, 2)\n",
        "      x = F.leaky_relu(self.enc_conv3(pool2), negative_slope=0.1)'''\n",
        "      pool3 = F.max_pool2d(x, 2) #MAKE SURE THEY HAVE CORRECT VALUES AND THEY ARE NOT CHANGED BY FOLLOWING OPERATIONS\n",
        "      x = F.leaky_relu(self.enc_conv4(pool3), negative_slope=0.1)\n",
        "      pool4 = F.max_pool2d(x, 2)\n",
        "      x = F.leaky_relu(self.enc_conv5(pool4), negative_slope=0.1)\n",
        "      ''' pool5 = F.max_pool2d(x, 2)\n",
        "      x = F.leaky_relu(self.enc_conv6(pool5), negative_slope=0.1)\n",
        "      x = self.upsample5(x)'''\n",
        "      x = torch.cat((x, pool4), dim=1)#.view(-1, 96, 2, 2) #MAKE SURE THEY ARE STACKED ON THE CORRECT DIMENSIONS\n",
        "      '''x = F.leaky_relu(self.dec_conv5a(x), negative_slope=0.1)\n",
        "      x = F.leaky_relu(self.dec_conv5b(x), negative_slope=0.1)\n",
        "      x = self.upsample4(x) \n",
        "      x = torch.cat((x, pool3), dim=1)\n",
        "      \n",
        "      x = F.leaky_relu(self.dec_conv4a(x), negative_slope=0.1)\n",
        "      x = F.leaky_relu(self.dec_conv4b(x), negative_slope=0.1)\n",
        "      x = self.upsample3(x) \n",
        "      x = torch.cat((x, pool2), dim=1)'''\n",
        "      x = self.upsample3(x) # custom\n",
        "      x = torch.cat((x, pool3), dim=1) #custom\n",
        "      x = F.leaky_relu(self.dec_conv3a(x), negative_slope=0.1)\n",
        "      x = F.leaky_relu(self.dec_conv3b(x), negative_slope=0.1)\n",
        "      x = self.upsample2(x) \n",
        "      #x = torch.cat((x, pool1), dim=1)\n",
        "      '''\n",
        "      x = F.leaky_relu(self.dec_conv2a(x), negative_slope=0.1)\n",
        "      x = F.leaky_relu(self.dec_conv2b(x), negative_slope=0.1)\n",
        "      x = self.upsample1(x) '''\n",
        "      x = torch.cat((x, input), dim=1)\n",
        "      #x = F.leaky_relu(self.custom(x), negative_slope=0.1) #custom\n",
        "      x = F.leaky_relu(self.dec_conv1a(x), negative_slope=0.1)\n",
        "      x = self.upsample1(x) #custom\n",
        "      x = F.leaky_relu(self.dec_conv1b(x), negative_slope=0.1)\n",
        "      x = F.max_pool2d(x, 2) #custom\n",
        "      x = self.dec_conv1c(x)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QD5d-nJvzFm7"
      },
      "outputs": [],
      "source": [
        "class LeanerModel(torch.nn.Module):\n",
        "    def __init__(self, transposed_conv=False):\n",
        "        super().__init__()\n",
        "        self.enc_conv0 = nn.Conv2d(3, 16, (3, 3), padding='same')\n",
        "        self.enc_conv1 = nn.Conv2d(16, 32, (3, 3), padding='same')\n",
        "        self.enc_conv3 = nn.Conv2d(32, 32, (3, 3), padding='same')\n",
        "                  # concatenation\n",
        "        self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "                  # concatenatio\n",
        "        self.dec_conv2a = nn.Conv2d(64, 64, (3, 3), padding='same')\n",
        "        self.dec_conv2b = nn.Conv2d(64, 64, (3, 3), padding='same')\n",
        "        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "                  # concatenation\n",
        "        self.dec_conv1a = nn.Conv2d(67, 32, (3, 3), padding='same')\n",
        "        self.dec_conv1b = nn.Conv2d(32, 16, (3, 3), padding='same')\n",
        "        self.dec_conv1c = nn.Conv2d(16, 3, (3, 3), padding='same')\n",
        "                  #what does linear activation mean (output unchanged?)\n",
        "\n",
        "    def forward(self, x):\n",
        "      input = x.clone()\n",
        "      x = F.leaky_relu(self.enc_conv0(x), negative_slope=0.1)\n",
        "      x = F.leaky_relu(self.enc_conv1(x), negative_slope=0.1)\n",
        "      pool1 = F.max_pool2d(x, 2) #32x16x16\n",
        "      x = F.leaky_relu(self.enc_conv3(pool1), negative_slope=0.1)\n",
        "      #pool3 = F.max_pool2d(x, 2) #48x8x8\n",
        "      #x = self.upsample2(x) #48x32x32\n",
        "      x = torch.cat((x, pool1), dim=1)#64x16x16\n",
        "      x = F.leaky_relu(self.dec_conv2a(x), negative_slope=0.1)\n",
        "      #x = F.leaky_relu(self.dec_conv2b(x), negative_slope=0.1)\n",
        "      x = self.upsample1(x)  #64x32x32\n",
        "      x = torch.cat((x, input), dim=1) #67x32x32\n",
        "      x = F.leaky_relu(self.dec_conv1a(x), negative_slope=0.1)\n",
        "      x = F.leaky_relu(self.dec_conv1b(x), negative_slope=0.1)\n",
        "      x = self.dec_conv1c(x)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2e3MRORcy05",
        "outputId": "9473f507-1b93-4a16-c8ea-126560fa7e63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ogXoYG1kJL19",
        "outputId": "dd1cc70e-314e-42a0-9ac7-1117b2178760"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Unable to find a valid cuDNN algorithm to run convolution",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32md:\\EPFL\\dl\\Miniproject1\\DeepLearning-project\\UNetNoise2Noise.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000009?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m LeanerModel()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000009?line=1'>2</a>\u001b[0m train_model(model, noisy_imgs1\u001b[39m.\u001b[39;49mfloat(), noisy_imgs2\u001b[39m.\u001b[39;49mfloat(), nn\u001b[39m.\u001b[39;49mMSELoss(), torch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdam(model\u001b[39m.\u001b[39;49mparameters(), betas\u001b[39m=\u001b[39;49m(\u001b[39m0.9\u001b[39;49m, \u001b[39m0.99\u001b[39;49m)), \u001b[39m25\u001b[39;49m, \u001b[39m10\u001b[39;49m)\n",
            "\u001b[1;32md:\\EPFL\\dl\\Miniproject1\\DeepLearning-project\\UNetNoise2Noise.ipynb Cell 8'\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_input, train_target, criterion, optimizer, mini_batch_size, epochs, normalize)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000005?line=9'>10</a>\u001b[0m avg_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000005?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, train_input\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), mini_batch_size):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000005?line=11'>12</a>\u001b[0m     output \u001b[39m=\u001b[39m model(train_input\u001b[39m.\u001b[39;49mnarrow(\u001b[39m0\u001b[39;49m, b, mini_batch_size))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000005?line=12'>13</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(output, train_target\u001b[39m.\u001b[39mnarrow(\u001b[39m0\u001b[39m, b, mini_batch_size))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000005?line=13'>14</a>\u001b[0m     avg_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n",
            "File \u001b[1;32mD:\\Programmi\\Python3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32md:\\EPFL\\dl\\Miniproject1\\DeepLearning-project\\UNetNoise2Noise.ipynb Cell 10'\u001b[0m in \u001b[0;36mLeanerModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000007?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000007?line=19'>20</a>\u001b[0m   \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mclone()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000007?line=20'>21</a>\u001b[0m   x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mleaky_relu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menc_conv0(x), negative_slope\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000007?line=21'>22</a>\u001b[0m   x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mleaky_relu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menc_conv1(x), negative_slope\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/EPFL/dl/Miniproject1/DeepLearning-project/UNetNoise2Noise.ipynb#ch0000007?line=22'>23</a>\u001b[0m   pool1 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmax_pool2d(x, \u001b[39m2\u001b[39m) \u001b[39m#32x16x16\u001b[39;00m\n",
            "File \u001b[1;32mD:\\Programmi\\Python3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mD:\\Programmi\\Python3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/conv.py?line=446'>447</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "File \u001b[1;32mD:\\Programmi\\Python3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    <a href='file:///d%3A/Programmi/Python3/lib/site-packages/torch/nn/modules/conv.py?line=443'>444</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Unable to find a valid cuDNN algorithm to run convolution"
          ]
        }
      ],
      "source": [
        "model = LeanerModel()\n",
        "train_model(model, noisy_imgs1.float(), noisy_imgs2.float(), nn.MSELoss(), torch.optim.Adam(model.parameters(), betas=(0.9, 0.99)), 25, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'leaner_model1_3.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un1oCewLJC9o",
        "outputId": "cf935d8f-4ce4-4857-b044-f1c357a65d49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24.442471048355102\n"
          ]
        }
      ],
      "source": [
        "model = LeanerModel()\n",
        "model.load_state_dict(torch.load('models/leaner_model1.pt'))\n",
        "print(validate(model.to(\"cuda\"), noisy_val.float(), clean_val.float()))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DummyCodeDL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
